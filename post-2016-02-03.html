<!doctype html>
<html>
<head>
    <script type="text/javascript" async
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
<body>
<H2> 2016-02-03 : Non-constant curvature log-likelihoods </H2>

 <p> I have been trying to think if I can come up with a likelihood with non-constant log-curvature, but which still produces integrable posteriors (i.e. the evidence can be calculated) when used with normal entropic priors.</p>

<p> Sadly, I don't think I can.</p>

<p> I had hoped that \(\frac{1}{x^2 + 1}\) might be useful, as it has reasonably non trivial gradients. 
$$ L = -\log\left(\frac{1}{x^2 + 1} \right) $$ 
$$ \frac{\partial L}{\partial x} = \frac{2x}{x^2 + 1}  $$ 
$$ \frac{\partial^2 L}{\partial x^2} = 2\frac{1-x^2}{\left(x^2 + 1\right)^2}  $$ 
but, the posterior form (for quadratic entropy) is not integrable
$$ E \propto \int \frac{\exp\left( -\frac{1}{2}(\frac{x-\mu}{\sigma})^2\right)}{x^2 + 1} \textrm{d}x $$
</p>

<p> Then it occurred to me that I don't need a properly integrable function. I'm trying to work this out to validate an inference system. This system only returns Gaussian approximations to the evidence, so I can validate it by comparing the real Gaussian approximation with what it has calculated. I only need to make sure that I can work out the curvature of the log-posterior at its peak. </p>

<p> Also the form of the prior used is actually slightly different, it is centered at zero. Also, to make things interesting, I'm going to make \(x\) the residual between some data and some linear model fit
$$ x_i = \frac{d_i - \sum_j R_{ij} h_j}{\sigma} $$

$$ E \propto \int \frac{\exp\left( -\frac{1}{2}\sum_j \frac{h^2_j}{m_i}\right)}{\prod_i x_i^2 + 1} \textrm{d}x $$

Considering the (unnormalised) log-posterior,
$$
Q = -\frac{1}{2}\sum_j \frac{h^2_j}{m_i} - \sum_i \log\left( \left(\frac{d_i - \sum_j R_{ij} h_j}{\sigma}\right)^2 + 1 \right)
$$

and its gradient

$$
\frac { \partial Q}{\partial h_k}  = - \frac{h_k}{m_i} - \sum_i \left( \left(\frac{d_i - \sum_j R_{ij} h_j}{\sigma}\right)^2 + 1 \right)^{-1} 2 \left(\frac{d_i - \sum_j R_{ij} h_j}{\sigma}\right) \frac{-R_{ik}}{\sigma}
$$

shows that finding the peak is going to be hard.
</body>
</html>